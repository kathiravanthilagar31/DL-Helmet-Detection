{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45efde32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# lib for pre trained model \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "# lib for layers\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "# lib for connecting pretrained and created model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "#lib for compile\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# lib for pre processing\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "# lib for spliting i/p and o/p\n",
    "from sklearn.model_selection import train_test_split\n",
    "# lib for metrics\n",
    "from sklearn.metrics import classification_report\n",
    "# other lib\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d95103f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "\n",
    "DIRECTORY = r\"C:\\HOPE\\Deep Learning\\Helmet detection\\dataset\"\n",
    "CATEGORIES = [\"with_Helmet\", \"without_Helmet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17d9daa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"[INFO] loading images...\")\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = load_img(img_path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "\n",
    "        data.append(image)\n",
    "        labels.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71d07999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "      test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f095c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc3b4802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kathi\\AppData\\Local\\Temp\\ipykernel_5416\\633592287.py:3: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n"
     ]
    }
   ],
   "source": [
    "# load the MobileNetV2 network, ensuring the head FC layer sets are\n",
    "# left off\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "       input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e50de3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compiling model....\n"
     ]
    }
   ],
   "source": [
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "print(\"[INFO] Compiling model....\")\n",
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "\n",
    "opt = SGD(learning_rate=INIT_LR)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer =opt,\n",
    "              metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "006cc5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training ahead....\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 752ms/step - accuracy: 0.3212 - loss: 1.1317 - val_accuracy: 0.2792 - val_loss: 0.9756\n",
      "Epoch 2/20\n",
      "\u001b[1m 1/61\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 479ms/step - accuracy: 0.3750 - loss: 1.0123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3750 - loss: 1.0123 - val_accuracy: 0.2857 - val_loss: 1.0343\n",
      "Epoch 3/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 733ms/step - accuracy: 0.3968 - loss: 0.9664 - val_accuracy: 0.3688 - val_loss: 0.8401\n",
      "Epoch 4/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5312 - loss: 0.8208 - val_accuracy: 0.2857 - val_loss: 0.8568\n",
      "Epoch 5/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 714ms/step - accuracy: 0.5222 - loss: 0.8240 - val_accuracy: 0.5021 - val_loss: 0.7371\n",
      "Epoch 6/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5938 - loss: 0.7880 - val_accuracy: 0.4286 - val_loss: 0.7836\n",
      "Epoch 7/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 695ms/step - accuracy: 0.6236 - loss: 0.7316 - val_accuracy: 0.6292 - val_loss: 0.6627\n",
      "Epoch 8/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5938 - loss: 0.7609 - val_accuracy: 0.7143 - val_loss: 0.7028\n",
      "Epoch 9/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 694ms/step - accuracy: 0.6979 - loss: 0.6626 - val_accuracy: 0.7292 - val_loss: 0.6084\n",
      "Epoch 10/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6875 - loss: 0.6904 - val_accuracy: 0.9286 - val_loss: 0.5536\n",
      "Epoch 11/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 693ms/step - accuracy: 0.7296 - loss: 0.6290 - val_accuracy: 0.7917 - val_loss: 0.5645\n",
      "Epoch 12/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7188 - loss: 0.6782 - val_accuracy: 0.8571 - val_loss: 0.5076\n",
      "Epoch 13/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 694ms/step - accuracy: 0.7580 - loss: 0.5995 - val_accuracy: 0.8250 - val_loss: 0.5306\n",
      "Epoch 14/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5938 - loss: 0.6857 - val_accuracy: 0.9286 - val_loss: 0.4675\n",
      "Epoch 15/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 694ms/step - accuracy: 0.7683 - loss: 0.5819 - val_accuracy: 0.8521 - val_loss: 0.4981\n",
      "Epoch 16/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7812 - loss: 0.4814 - val_accuracy: 0.7143 - val_loss: 0.5878\n",
      "Epoch 17/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 689ms/step - accuracy: 0.7908 - loss: 0.5281 - val_accuracy: 0.8521 - val_loss: 0.4768\n",
      "Epoch 18/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.3672 - val_accuracy: 0.8571 - val_loss: 0.5259\n",
      "Epoch 19/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 695ms/step - accuracy: 0.8163 - loss: 0.5140 - val_accuracy: 0.8542 - val_loss: 0.4616\n",
      "Epoch 20/20\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.4005 - val_accuracy: 0.9286 - val_loss: 0.3912\n"
     ]
    }
   ],
   "source": [
    "# train the head of the network\n",
    "# calculating steps per epoch and validation steps\n",
    "steps_per_epoch = len(trainX)//BS\n",
    "validation_steps = len(testX)//BS\n",
    "\n",
    "# Use .repeat() to ensure the dataset generates enough batches\n",
    "train_data_gen = aug.flow(trainX, trainY, batch_size=BS)\n",
    "validation_data_gen = ImageDataGenerator().flow(testX, testY, batch_size=BS)\n",
    "\n",
    "#train the model\n",
    "\n",
    "print(\"[INFO] training ahead....\")\n",
    "H = model.fit(train_data_gen,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_data = validation_data_gen,\n",
    "              validation_steps=validation_steps,\n",
    "              epochs =EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a2a899a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 494ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d431bd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "   with_Helmet       0.95      0.36      0.52       108\n",
      "without_Helmet       0.85      0.99      0.92       386\n",
      "\n",
      "      accuracy                           0.86       494\n",
      "     macro avg       0.90      0.68      0.72       494\n",
      "  weighted avg       0.87      0.86      0.83       494\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(testY.argmax(axis =1), predIdxs, target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98ba8135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving the helmet detector model...\n"
     ]
    }
   ],
   "source": [
    "#Save the model\n",
    "print(\"[INFO] saving the helmet detector model...\")\n",
    "model.save('helmet_detector.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11eba9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
